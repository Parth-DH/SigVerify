{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parth-DH/SigVerify/blob/master/V_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OFbEtFpfKO3",
        "colab_type": "text"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQc_t2y-xNxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPOZb-KbPpGn",
        "colab_type": "code",
        "outputId": "1b4df6bc-75c2-4719-c924-3f8345c9064f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd var"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/var\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-YqSOwwJZRF",
        "colab_type": "code",
        "outputId": "2b70bf8f-44db-4cfa-dcd5-05bf5a5ab038",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-852d026a-de31-4722-be10-327094e7bf14\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-852d026a-de31-4722-be10-327094e7bf14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ICDAR_DATA_1.zip to ICDAR_DATA_1.zip\n",
            "User uploaded file \"ICDAR_DATA_1.zip\" with length 4681115 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wJuzPuoNRz_",
        "colab_type": "code",
        "outputId": "a22a8f99-a161-4cbd-d1d0-0cd6f6240389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9010
        }
      },
      "source": [
        "!unzip ICDAR_DATA_1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ICDAR_DATA_1.zip\n",
            "   creating: ICDAR_Data/\n",
            "   creating: ICDAR_Data/Train_Data/\n",
            "   creating: ICDAR_Data/Train_Data/authentic/\n",
            "   creating: ICDAR_Data/Train_Data/authentic/fifteen/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/fifteen/015_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/forteen/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/forteen/014_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/four/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/four/004_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/NINE/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/NINE/009_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/one/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/one/001_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/six/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/six/006_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/sixeteen/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/sixeteen/016_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/three/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/three/003_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/twelve/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/twelve/012_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/authentic/two/\n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/authentic/two/002_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/\n",
            "   creating: ICDAR_Data/Eval/authentic/\n",
            "   creating: ICDAR_Data/Eval/authentic/fifteen/\n",
            "  inflating: ICDAR_Data/Eval/authentic/fifteen/015_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/fifteen/015_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/fifteen/015_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/fifteen/015_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/fifteen/015_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/forteen/\n",
            "  inflating: ICDAR_Data/Eval/authentic/forteen/014_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/forteen/014_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/forteen/014_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/forteen/014_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/forteen/014_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/four/\n",
            "  inflating: ICDAR_Data/Eval/authentic/four/004_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/four/004_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/four/004_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/four/004_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/four/004_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/NINE/\n",
            "  inflating: ICDAR_Data/Eval/authentic/NINE/009_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/NINE/009_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/NINE/009_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/NINE/009_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/NINE/009_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/one/\n",
            "  inflating: ICDAR_Data/Eval/authentic/one/001_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/one/001_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/one/001_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/one/001_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/one/001_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/six/\n",
            "  inflating: ICDAR_Data/Eval/authentic/six/006_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/six/006_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/six/006_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/six/006_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/six/006_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/sixeteen/\n",
            "  inflating: ICDAR_Data/Eval/authentic/sixeteen/016_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/sixeteen/016_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/sixeteen/016_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/sixeteen/016_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/sixeteen/016_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/three/\n",
            "  inflating: ICDAR_Data/Eval/authentic/three/003_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/three/003_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/three/003_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/three/003_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/three/003_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/twelve/\n",
            "  inflating: ICDAR_Data/Eval/authentic/twelve/012_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/twelve/012_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/twelve/012_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/twelve/012_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/twelve/012_24.jpg  \n",
            "   creating: ICDAR_Data/Eval/authentic/two/\n",
            "  inflating: ICDAR_Data/Eval/authentic/two/002_20.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/two/002_21.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/two/002_22.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/two/002_23.jpg  \n",
            "  inflating: ICDAR_Data/Eval/authentic/two/002_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/fifteen/\n",
            "   creating: ICDAR_Data/Train_Data/fifteen/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_19.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_20.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_21.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_22.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_23.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/fifteen/char1/015_24.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/forteen/\n",
            "   creating: ICDAR_Data/Train_Data/forteen/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/forteen/char1/014_19.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/four/\n",
            "   creating: ICDAR_Data/Train_Data/four/New folder/\n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/four/New folder/004_19.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/NINE/\n",
            "   creating: ICDAR_Data/Train_Data/NINE/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/NINE/char1/009_19.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/one/\n",
            "   creating: ICDAR_Data/Train_Data/one/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/one/char1/001_19.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/six/\n",
            "   creating: ICDAR_Data/Train_Data/six/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/six/char1/006_19.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/sixeteen/\n",
            "   creating: ICDAR_Data/Train_Data/sixeteen/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/sixeteen/char1/016_18.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/three/\n",
            "   creating: ICDAR_Data/Train_Data/three/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/three/char1/003_19.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/twelve/\n",
            "   creating: ICDAR_Data/Train_Data/twelve/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/twelve/char1/012_19.jpg  \n",
            "   creating: ICDAR_Data/Train_Data/two/\n",
            "   creating: ICDAR_Data/Train_Data/two/char1/\n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_01.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_02.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_03.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_04.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_05.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_06.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_07.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_08.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_09.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_10.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_11.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_12.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_13.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_14.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_15.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_16.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_17.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_18.jpg  \n",
            "  inflating: ICDAR_Data/Train_Data/two/char1/002_19.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJNbgXdCOn7F",
        "colab_type": "code",
        "outputId": "e4f16833-bbcb-4a3b-bb93-d3e81afaaa38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/var\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0Dbr_zcUQBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.legacy import interfaces\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Optimizer\n",
        "\n",
        "class Modified_SGD(Optimizer):\n",
        "  \"\"\" Modified Stochastic gradient descent optimizer.\n",
        "  Almost all this class is Keras SGD class code. I just reorganized it\n",
        "  in this class to allow layer-wise momentum and learning-rate\n",
        "  Includes support for momentum,\n",
        "  learning rate decay, and Nesterov momentum.\n",
        "  Includes the possibility to add multipliers to different\n",
        "  learning rates in each layer.\n",
        "  # Arguments\n",
        "  lr: float >= 0. Learning rate.\n",
        "  momentum: float >= 0. Parameter updates momentum.\n",
        "  decay: float >= 0. Learning rate decay over each update.\n",
        "        nesterov: boolean. Whether to apply Nesterov momentum.\n",
        "        lr_multipliers: dictionary with learning rate for a specific layer\n",
        "        for example:\n",
        "            # Setting the Learning rate multipliers\n",
        "            LR_mult_dict = {}\n",
        "            LR_mult_dict['c1']=1\n",
        "            LR_mult_dict['c2']=1\n",
        "            LR_mult_dict['d1']=2\n",
        "            LR_mult_dict['d2']=2\n",
        "        momentum_multipliers: dictionary with momentum for a specific layer \n",
        "        (similar to the lr_multipliers)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, lr=0.01, momentum=0., decay=0.,\n",
        "                 nesterov=False, lr_multipliers=None, momentum_multipliers=None, **kwargs):\n",
        "    super(Modified_SGD, self).__init__(**kwargs)\n",
        "    with K.name_scope(self.__class__.__name__):\n",
        "      self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "      self.lr = K.variable(lr, name='lr')\n",
        "      self.momentum = K.variable(momentum, name='momentum')\n",
        "      self.decay = K.variable(decay, name='decay')\n",
        "    self.initial_decay = decay\n",
        "    self.nesterov = nesterov\n",
        "    self.lr_multipliers = lr_multipliers\n",
        "    self.momentum_multipliers = momentum_multipliers\n",
        "\n",
        "    @interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "      grads = self.get_gradients(loss, params)\n",
        "      self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "      lr = self.lr\n",
        "      if self.initial_decay > 0:\n",
        "        lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
        "                                                  K.dtype(self.decay))))\n",
        "        \n",
        "        \n",
        "      # momentum\n",
        "      shapes = [K.int_shape(p) for p in params]\n",
        "      moments = [K.zeros(shape) for shape in shapes]\n",
        "      self.weights = [self.iterations] + moments\n",
        "      for p, g, m in zip(params, grads, moments):\n",
        "\n",
        "        if self.lr_multipliers != None:\n",
        "          if p.name in self.lr_multipliers:\n",
        "            new_lr = lr * self.lr_multipliers[p.name]\n",
        "          else:\n",
        "            new_lr = lr\n",
        "        else:\n",
        "          new_lr = lr\n",
        "\n",
        "        if self.momentum_multipliers != None:\n",
        "          if p.name in self.momentum_multipliers:\n",
        "            new_momentum = self.momentum * \\\n",
        "                        self.momentum_multipliers[p.name]\n",
        "          else:\n",
        "            new_momentum = self.momentum\n",
        "        else:\n",
        "          new_momentum = self.momentum\n",
        "\n",
        "        v = new_momentum * m - new_lr * g  # velocity\n",
        "        self.updates.append(K.update(m, v))\n",
        "\n",
        "        if self.nesterov:\n",
        "          new_p = p + new_momentum * v - new_lr * g\n",
        "        else:\n",
        "          new_p = p + v\n",
        "\n",
        "        # Apply constraints.\n",
        "        if getattr(p, 'constraint', None) is not None:\n",
        "          ew_p = p.constraint(new_p)\n",
        "\n",
        "        self.updates.append(K.update(p, new_p))\n",
        "    return self.updates\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'momentum': float(K.get_value(self.momentum)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'nesterov': self.nesterov,\n",
        "                  'lr_multipliers': float(K.get_value(self.lr_multipliers)),\n",
        "                  'momentum_multipliers': float(K.get_value(self.momentum_multipliers))}\n",
        "    base_config = super(Modified_SGD, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyAt0URdAbKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "class ICDAR_Loader:\n",
        "  \"\"\"class that loads and prepares the ICDAR Dataset\"\"\"\n",
        "  def __init__(self, dataset_path, batch_size):\n",
        "    self.dataset_path=dataset_path\n",
        "    self.train_dictionary={}\n",
        "    self.evaluation_dictionary={}\n",
        "    self.image_width=200\n",
        "    self.image_height=200\n",
        "    self.batch_size=batch_size\n",
        "    self.train=[]\n",
        "    self.val=[]\n",
        "    self.eval=[]\n",
        "    self.cti=0\n",
        "    self.cvi=0\n",
        "    self.cei=0\n",
        "    self.load_dataset()\n",
        "  def load_dataset(self):\n",
        "    train_path=os.path.join(self.dataset_path, 'Train_Data')\n",
        "    validation_path=os.path.join(self.dataset_path, 'Eval')\n",
        "    \n",
        "    for sig in os.listdir(train_path):\n",
        "      print(sig)\n",
        "      sig_path=os.path.join(train_path, sig)\n",
        "      \n",
        "      curr_sig_dict={}\n",
        "      for char in os.listdir(sig_path):\n",
        "        char_path=os.path.join(sig_path, char)\n",
        "        curr_sig_dict[char]=os.listdir(char_path)\n",
        "      self.train_dictionary[sig]=curr_sig_dict\n",
        "      \n",
        "    for sig in os.listdir(validation_path):\n",
        "      sig_path=os.path.join(validation_path, sig)\n",
        "      \n",
        "      curr_sig_dict={}\n",
        "      for char in os.listdir(sig_path):\n",
        "        char_path=os.path.join(sig_path, char)\n",
        "        curr_sig_dict[char]=os.listdir(char_path)\n",
        "      self.evaluation_dictionary[sig]=curr_sig_dict\n",
        "     \n",
        "  def split_train_dataset(self):\n",
        "    \"\"\"Splits the train set into training and validation\"\"\"\n",
        "    available_sig = list(self.train_dictionary.keys())\n",
        "    number_of_sig = len(available_sig)\n",
        "    train_indexes = random.sample(range(0, number_of_sig -1), int(0.8*number_of_sig))\n",
        "    train_indexes.sort(reverse=True)\n",
        "    \n",
        "    for index in train_indexes:\n",
        "      self.train.append(available_sig[index])\n",
        "      print(self.train)\n",
        "      available_sig.pop(index)\n",
        "    \n",
        "    self.val=available_sig\n",
        "    self.eval=list(self.evaluation_dictionary.keys())\n",
        "    \n",
        "  def _convert_path_list_to_image_and_labels(self, path_list, is_one_shot_task):\n",
        "    \"\"\"loads image and correstponding lables from the path\"\"\"\n",
        "    number_of_pairs = int(len(path_list)/2)\n",
        "    pairs_of_images = [np.zeros((number_of_pairs, self.image.height, 1)) for i in range(2)]\n",
        "    labels=np.zeros((number_of_pairs, 1))\n",
        "    \n",
        "    for pair in range(number_of_pairs):\n",
        "      image=Image.open(path_list[pair *2])\n",
        "      image = np.asarray(image).astype(np.float64)\n",
        "      image = image/ image.std() - image.mean()\n",
        "      \n",
        "      pairs_of_images[0][pair, :, :, 0] = image\n",
        "      image = Image.open(path_list[pair *2 +1])\n",
        "      image = np.asarray(image).astype(float64)\n",
        "      image = image / image.std() - image.mean()\n",
        "      \n",
        "      pairs_of_images[1][pair, :, :, 0] = image\n",
        "      \n",
        "      if not is_one_shot_task:\n",
        "        if(pair+1)%2==0:\n",
        "          labels[pair] = 0\n",
        "        else:\n",
        "          labels[pair] = 1\n",
        "      else:\n",
        "        if pair == 0:\n",
        "          labels[pair]=1\n",
        "        else:\n",
        "          labels[pair]=0\n",
        "   \n",
        "    if not is_one_shot_task:\n",
        "      random_permutation = np.random.permutation(number_of_pairs)\n",
        "      labels = labels[random_permutation]\n",
        "      pairs_of_images[0][:, :, :, :] = pairs_of_images[0][random_permutation, :, :, :]\n",
        "      pairs_of_images[1][:, :, :, :] = pairs_of_images[1][random_permutation, :, :, :]\n",
        "\n",
        "    return pairs_of_images, labels\n",
        "\n",
        "  def get_train_batch(self):\n",
        "    print(self.train)\n",
        "    print(self.cti)\n",
        "    curr_sig=self.train[self.cti]\n",
        "    avail_chars = list(self.train_dictionary[curr_sig].keys())\n",
        "    number_of_chars=len(avail_chars)\n",
        "  \n",
        "    batch_image_path=[]\n",
        "  \n",
        "    selected_chars_indexes = [random.randit(0, number_of_chars-1) for i in range(self.batch_size)]\n",
        "    for index in selected_chars_indexes:\n",
        "      current_char = avail_chars[index]\n",
        "      available_images = (self.train_dictionary[curr_sig])[curr_char]\n",
        "    \n",
        "      image_path= os.path.join(self.dataset_path, 'Train_Data', curr_sig, curr_char)\n",
        "      image_indexes = random.sample(range(0, 10), 3)\n",
        "      image = os.path.join(image_path, available_images[image_indexes[0]])\n",
        "      batch_images_path.append(image)\n",
        "      image= os.path.join(image_path, available_images[image_indexes[1]])\n",
        "      batch_images_path.append(image)\n",
        "    \n",
        "      \"\"\"pairs from different sigs\"\"\"\n",
        "      image = os.path.join(image_path, available_images[image_indexes[2]])\n",
        "      bacth_images_path.append(image)\n",
        "      different_characters = avail_chars[:]\n",
        "      different_characters.pop(index)\n",
        "      different_character_index = random.sample(range(0, number_of_chars - 1), 1)\n",
        "      curr_char = different_characters[different_character_index[0]]\n",
        "      available_images = (self.train_dictionary[curr_sig])[curr_char]\n",
        "      image_indexes = random.sample(range(0, 20), 1)\n",
        "      image_path = os.path.join(self.dataset_path, 'Train_Daata', curr_sig, curr_char)\n",
        "      image = os.path.join(image_path, available_images[image_indexes[0]])\n",
        "      batch_images_path.append(image)\n",
        "  \n",
        "    self.cti+=1\n",
        "    if(self.cti >14):\n",
        "      self.cti = 0\n",
        "    images, labels = self._convert_path_list_to_image_and_labels(batch_images_path, is_one_shot_task=False)\n",
        "  \n",
        "    return images, labels\n",
        "\n",
        "  def get_one_shot_batch(self, support_set_size, is_validation):\n",
        "    '''loads and returns batch of one shot learning task images'''\n",
        "    if is_validation:\n",
        "      chars=self.val\n",
        "      curr_char_index= self.cvi\n",
        "      image_folder_name = 'Train_Data'\n",
        "      dictionary=self.train_dictionary\n",
        "    else:\n",
        "      chars=self.eval\n",
        "      curr_char_index=self.cei\n",
        "      image_folder_name='images_eval'\n",
        "      dictionary=self.evaluation_dictionary\n",
        "    curr_char= chars[curr_char_index]\n",
        "    avail_chars = list(dictionary[curr_char].keys())\n",
        "    number_of_characters = len(avail_chars)\n",
        "  \n",
        "    batch_images_path = []\n",
        "  \n",
        "    test_char_index=random.sample(range(0, number_of_characters), 1)\n",
        "    #get test image\n",
        "    curr_char=avail_char[test_char_index[0]]\n",
        "    available_images = (dictionary[curr_sig])[curr_char]\n",
        "    image_indexes = random.sample(range(0, 20), 2)\n",
        "    image_path=os.path.join(self.dataset_path, image_folder_name, curr_sig, curr_char)\n",
        "  \n",
        "    test_image= os.path.join(image_path, available_images[image_indexes[0]])\n",
        "    batch_images_path.append(test_image)\n",
        "    image=os.path.join(image_path, available_images[image_indexes[1]])\n",
        "    batch_images_path.append(image)\n",
        "  \n",
        "    if support_test_size== -1:\n",
        "      number_of_support_characters=number_of_characters\n",
        "    else:\n",
        "      number_of_support_characters= support_set_size\n",
        "   \n",
        "    different_characters = available_characters[:]\n",
        "    different_characters.pop(test_character_index[0])\n",
        "  \n",
        "    if number_of_characters < number_of_support_characters:\n",
        "      number_of_support_characters = number_of_characters\n",
        "    support_characters_indexes = random.sample(range(0, number_of_characters-1), number_of_support_characters -1)\n",
        "    for index in support_characters_indexes:\n",
        "      curr_char= different_characters[index]\n",
        "      available_images=(dictionary[curr_sig])[curr_char]\n",
        "      image_path = os.path.join(self.dataset_path, image_folder_name, curr_sig, curr_char)\n",
        "      image_indexes=random.sample(range(0, 20), 1)\n",
        "      image = os.path.join(image_path, available_images[image_indexes[0]])\n",
        "      batch_images_path.append(test_image)\n",
        "      batch_images_path.append(image)\n",
        "    images, labels = self._convert_path_list_to_image_and_labels(batch_images_path, is_one_shot_task = True)\n",
        "  \n",
        "    return images, labels\n",
        "  \n",
        "  def one_shot_test(self, support_set_size, number_of_tasks_per_sig, is_validation):\n",
        "    if is_validation:\n",
        "      sigs= self.val\n",
        "      print('\\nMaking One Shot Task on validation alphabets:')\n",
        "    else:\n",
        "      sigs=self.eval\n",
        "      print('\\nMaking One Shot Task on evaluation alphabets:')\n",
        "    mean_global_accuracy = 0\n",
        "    \n",
        "    for sig in sigs:\n",
        "      mean_alphabet_accuracy=0\n",
        "      for _ in range(number_of_tasks_per_sig):\n",
        "        images, _= self.get_one_shot_batch(support_set_size, is_validation=is_validation)\n",
        "        probabilities=model.predict_on_batch(images)\n",
        "        \n",
        "        if np.argmax(probabilities)==0 and probabilities.std()>0.01:\n",
        "          accuracy=1.0\n",
        "        else:\n",
        "          accuracy=0.0\n",
        "          \n",
        "        mean_sig_accuracy+=accuracy\n",
        "        mean_global_accuracy+= accuracy\n",
        "      mean_sig_accuracy /= number_of_tasks_per_sig\n",
        "      print(sig + 'signature' + ', accuracy: ' + str(mean_sig_accuracy))\n",
        "      if is_validation:\n",
        "        self.cvi+=1\n",
        "      else:\n",
        "        self.cei+=1\n",
        "    mean_global_accuracy /= (len(sigs)*number_of_tasks_per_sig)\n",
        "    print('\\nMean global accuracy: ' + str(mean_global_accuracy))\n",
        "    \n",
        "    if is_validation:\n",
        "      self.cvi=0\n",
        "    else:\n",
        "      self.cei=0\n",
        "    return mean_global_accuracy\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIeN0shkExX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Input, Subtract, Lambda\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l2\n",
        "import keras.backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmSF2iPog2zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiameseNetwork:\n",
        "  \"\"\"construct SNET for training\"\"\"\n",
        "  def __init__(self, dataset_path, learning_rate, batch_size, learning_rate_multipliers, l2_regularization_penalization, tensorboard_log_path):\n",
        "    self.input_shape = (200, 200, 1)\n",
        "    self.model = []\n",
        "    self.learning_rate = learning_rate\n",
        "    self.ICDAR_loader = ICDAR_Loader(dataset_path=dataset_path, batch_size=batch_size)\n",
        "    self.summary_writer = tf.summary.FileWriter(tensorboard_log_path)\n",
        "    self.learning_rate_multipliers=learning_rate_multipliers\n",
        "    self.l2_regularization_penalization=l2_regularization_penalization\n",
        "    self.tensorboard_log_path=tensorboard_log_path\n",
        "  def __construct_siamese_architecture(self):\n",
        "    convolutional_net = Sequential()\n",
        "    convolutional_net.add(Conv2D(filters=64, kernel_size=(10, 10),\n",
        "                                     activation='relu',\n",
        "                                     input_shape=self.input_shape,\n",
        "                                     kernel_regularizer=l2(\n",
        "                                         l2_regularization_penalization['Conv1']),\n",
        "                                     name='Conv1'))\n",
        "    convolutional_net.add(MaxPool2D())\n",
        "\n",
        "    convolutional_net.add(Conv2D(filters=128, kernel_size=(7, 7),\n",
        "                                     activation='relu',\n",
        "                                     kernel_regularizer=l2(\n",
        "                                         l2_regularization_penalization['Conv2']),\n",
        "                                     name='Conv2'))\n",
        "    convolutional_net.add(MaxPool2D())\n",
        "\n",
        "    convolutional_net.add(Conv2D(filters=128, kernel_size=(4, 4),\n",
        "                                     activation='relu',\n",
        "                                     kernel_regularizer=l2(\n",
        "                                         l2_regularization_penalization['Conv3']),\n",
        "                                     name='Conv3'))\n",
        "    convolutional_net.add(MaxPool2D())\n",
        "\n",
        "    convolutional_net.add(Conv2D(filters=256, kernel_size=(4, 4),\n",
        "                                     activation='relu',\n",
        "                                     kernel_regularizer=l2(\n",
        "                                         l2_regularization_penalization['Conv4']),\n",
        "                                     name='Conv4'))\n",
        "    convolutional_net.add(MaxPool2D())\n",
        "\n",
        "    convolutional_net.add(Flatten())\n",
        "    convolutional_net.add(\n",
        "            Dense(units=4096, activation='sigmoid',\n",
        "                  kernel_regularizer=l2(\n",
        "                      l2_regularization_penalization['Dense1']),\n",
        "                  name='Dense1'))\n",
        "\n",
        "        # Now the pairs of images\n",
        "    input_image_1 = Input(self.input_shape)\n",
        "    input_image_2 = Input(self.input_shape)\n",
        "  \n",
        "    encoded_image_1 = convolutional_net(input_image_1)\n",
        "    encoded_image_2 = convolutional_net(input_image_2)\n",
        "\n",
        "        # L1 distance layer between the two encoded outputs\n",
        "        # One could use Subtract from Keras, but we want the absolute value\n",
        "    l1_distance_layer = Lambda(\n",
        "              lambda tensors: K.abs(tensors[0] - tensors[1]))\n",
        "    l1_distance = l1_distance_layer([encoded_image_1, encoded_image_2])\n",
        "\n",
        "        # Same class or not prediction\n",
        "    prediction = Dense(units=1, activation='sigmoid')(l1_distance)\n",
        "    self.model = Model(\n",
        "            inputs=[input_image_1, input_image_2], outputs=prediction)\n",
        "\n",
        "        # Define the optimizer and compile the model\n",
        "    optimizer = Modified_SGD(\n",
        "            lr=self.learning_rate,\n",
        "            lr_multipliers=self.learning_rate_multipliers,\n",
        "            momentum=0.5)\n",
        "\n",
        "    self.model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'],\n",
        "                           optimizer=optimizer)\n",
        "  def __write_logs_to_tensorboard(self, current_iteration, train_losses, train_accuracies, validation_accuracy, evaluate_each):\n",
        "    summary = tf.summary()\n",
        "    \n",
        "    for index in range(0, evaluate_each):\n",
        "      value = summary.value.add()\n",
        "      value.simple_value=train_losses[index]\n",
        "      value.tag = 'Train Loss'\n",
        "\n",
        "      value = summary.value.add()\n",
        "      value.simple_value = train_accuracies[index]\n",
        "      value.tag = 'Train Accuracy'\n",
        "\n",
        "      if index == (evaluate_each - 1):\n",
        "        value = summary.value.add()\n",
        "        value.simple_value = validation_accuracy\n",
        "        value.tag = 'One-Shot Validation Accuracy'\n",
        "\n",
        "      self.summary_writer.add_summary(\n",
        "            summary, current_iteration - evaluate_each + index + 1)\n",
        "      self.summary_writer.flush()\n",
        "  def train_siamese_network(self, number_of_iterations, support_set_size, final_momentum, momentum_slope, evaluate_each, model_name):\n",
        "    self.ICDAR_loader.split_train_dataset()\n",
        "    train_losses=np.zeros(shape=(evaluate_each))\n",
        "    train_accuracies= np.zeros(shape=(evaluate_each))\n",
        "    count = 0\n",
        "    earrly_stop = 0\n",
        "    best_validation_accuracy=0.0\n",
        "    best_accuracy_iteration=0.0\n",
        "    validation_accuracy=0.0\n",
        "    \n",
        "    #train loop\n",
        "    for iteration in range(number_of_iterations):\n",
        "      #train set\n",
        "      images, labels= self.ICDAR_loader.get_train_batch()\n",
        "      train_loss, train_accuracy=self.model.train_on_batch(images, labels)\n",
        "      # Decay learning rate 1 % per 500 iterations (in the paper the decay is\n",
        "      # 1% per epoch). Also update linearly the momentum (starting from 0.5 to 1)\n",
        "      if (iteration +1)%500==0:\n",
        "        K.set_value(self.model.optimizer.lr, K.get_value(\n",
        "                    self.model.optimizer.lr) * 0.99)\n",
        "      if K.get_value(self.model.optimizer.momentum) < final_momentum:\n",
        "        K.set_value(self.model.optimizer.momentum, K.get_value(\n",
        "        self.model.optimizer.momentum) + momentum_slope)\n",
        "      train_losses[count] = train_loss\n",
        "      train_accuracies[count] = train_accuracy\n",
        "      \n",
        "      #validation set\n",
        "      count += 1\n",
        "      print('Iteration %d/%d: Train loss: %f, Train Accuracy: %f, lr = %f' %\n",
        "      (iteration + 1, number_of_iterations, train_loss, train_accuracy, K.get_value(\n",
        "                      self.model.optimizer.lr)))\n",
        "      # Each 100 iterations perform a one_shot_task and write to tensorboard the\n",
        "      # stored losses and accuracies\n",
        "      if (iteration + 1) % evaluate_each == 0:\n",
        "        number_of_runs_per_alphabet = 40\n",
        "        # use a support set size equal to the number of character in the alphabet\n",
        "        validation_accuracy = self.omniglot_loader.one_shot_test(\n",
        "                    self.model, support_set_size, number_of_runs_per_alphabet, is_validation=True)\n",
        "\n",
        "        self.__write_logs_to_tensorboard(\n",
        "                    iteration, train_losses, train_accuracies,\n",
        "                    validation_accuracy, evaluate_each)\n",
        "        count = 0\n",
        "        # Some hyperparameters lead to 100%, although the output is almost the same in \n",
        "        # all images. \n",
        "        if (validation_accuracy == 1.0 and train_accuracy == 0.5):\n",
        "          print('Early Stopping: Gradient Explosion')\n",
        "          print('Validation Accuracy = ' +\n",
        "                          str(best_validation_accuracy))\n",
        "          return 0\n",
        "        elif train_accuracy == 0.0:\n",
        "          return 0\n",
        "        else:\n",
        "          # Save the model\n",
        "          if validation_accuracy > best_validation_accuracy:\n",
        "            best_validation_accuracy = validation_accuracy\n",
        "            best_accuracy_iteration = iteration\n",
        "                        \n",
        "            model_json = self.model.to_json()\n",
        "\n",
        "            if not os.path.exists('./models'):\n",
        "              os.makedirs('./models')\n",
        "            with open('models/' + model_name + '.json', \"w\") as json_file:\n",
        "              json_file.write(model_json)\n",
        "            self.model.save_weights('models/' + model_name + '.h5')\n",
        "      if iteration - best_accuracy_iteration > 10000:\n",
        "        print('Early Stopping: validation accuracy did not increase for 10000 iterations')\n",
        "        print('Best Validation Accuracy = ' + str(best_validation_accuracy))\n",
        "        print('Validation Accuracy = ' + str(best_validation_accuracy))\n",
        "        break  \n",
        "    print('Trained Ended!')\n",
        "    return best_validation_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DqKaHoOpI0y",
        "colab_type": "code",
        "outputId": "0487684c-6023-4e9e-c502-455aa2e1dee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "def main():\n",
        "    dataset_path = 'var/ICDAR_Data'\n",
        "    learning_rate = 10e-4\n",
        "    batch_size = 32\n",
        "    # Learning Rate multipliers for each layer\n",
        "    learning_rate_multipliers = {}\n",
        "    learning_rate_multipliers['Conv1'] = 1\n",
        "    learning_rate_multipliers['Conv2'] = 1\n",
        "    learning_rate_multipliers['Conv3'] = 1\n",
        "    learning_rate_multipliers['Conv4'] = 1\n",
        "    learning_rate_multipliers['Dense1'] = 1\n",
        "    # l2-regularization penalization for each layer\n",
        "    l2_penalization = {}\n",
        "    l2_penalization['Conv1'] = 1e-2\n",
        "    l2_penalization['Conv2'] = 1e-2\n",
        "    l2_penalization['Conv3'] = 1e-2\n",
        "    l2_penalization['Conv4'] = 1e-2\n",
        "    l2_penalization['Dense1'] = 1e-4\n",
        "    # Path where the logs will be saved\n",
        "    tensorboard_log_path = './logs/siamese_net_lr10e-4'\n",
        "    siamese_network = SiameseNetwork(\n",
        "        dataset_path=dataset_path,\n",
        "        learning_rate=learning_rate,\n",
        "        batch_size=batch_size,\n",
        "        learning_rate_multipliers=learning_rate_multipliers,\n",
        "        l2_regularization_penalization=l2_penalization,\n",
        "        tensorboard_log_path=tensorboard_log_path\n",
        "    )\n",
        "    # Final layer-wise momentum (mu_j in the paper)\n",
        "    momentum = 0.9\n",
        "    # linear epoch slope evolution\n",
        "    momentum_slope = 0.01\n",
        "    support_set_size = 20\n",
        "    evaluate_each = 1000\n",
        "    number_of_train_iterations = 1000000\n",
        "\n",
        "    validation_accuracy = siamese_network.train_siamese_network(number_of_iterations=number_of_train_iterations,\n",
        "                                                                support_set_size=support_set_size,\n",
        "                                                                final_momentum=momentum,\n",
        "                                                                momentum_slope=momentum_slope,\n",
        "                                                                evaluate_each=evaluate_each, \n",
        "                                                                model_name='siamese_net_lr10e-4')\n",
        "    if validation_accuracy == 0:\n",
        "        evaluation_accuracy = 0\n",
        "    else:\n",
        "        # Load the weights with best validation accuracy\n",
        "        siamese_network.model.load_weights('.models/siamese_net_lr10e-4.h5')\n",
        "        evaluation_accuracy = siamese_network.omniglot_loader.one_shot_test(siamese_network.model,\n",
        "                                                                        20, 40, False)\n",
        "    \n",
        "    print('Final Evaluation Accuracy = ' + str(evaluation_accuracy))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    cwd=os.getcwd()\n",
        "    print(os.listdir(cwd))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-cf6fac3d9b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-cf6fac3d9b1b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlearning_rate_multipliers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_multipliers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0ml2_regularization_penalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2_penalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtensorboard_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensorboard_log_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Final layer-wise momentum (mu_j in the paper)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-a3a22bfb2315>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, learning_rate, batch_size, learning_rate_multipliers, l2_regularization_penalization, tensorboard_log_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mICDAR_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mICDAR_Loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard_log_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate_multipliers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_multipliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-dce296c464c2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcei\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train_Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-dce296c464c2>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mvalidation_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0msig_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'var/ICDAR_Data/Train_Data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWqcxngnMSFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    '''\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVkEyouRH45b",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}